{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5EtA08M_SA1",
        "outputId": "be28c9a1-fdc3-4ab4-cca8-2f737a6681cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision torchaudio --upgrade\n",
        "!pip install pillow numpy matplotlib\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGlI3PdDIWJd",
        "outputId": "9f257df4-b960-406c-b4f1-f175ac9c4b7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.9.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: ultralytics in /usr/local/lib/python3.12/dist-packages (8.3.235)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.3)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.3)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.9.1)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.24.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: polars>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.31.0)\n",
            "Requirement already satisfied: ultralytics-thop>=2.0.18 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.18)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.11.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import copy\n",
        "import time\n",
        "import shutil\n",
        "from PIL import Image\n",
        "from torchvision import transforms, datasets, models\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.datasets.folder import IMG_EXTENSIONS\n",
        "from ultralytics import YOLO"
      ],
      "metadata": {
        "id": "KMUjKiU1JtX6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset\"\n",
        "train_dir = dataset_path + \"/train\"\n",
        "validation_dir = dataset_path + \"/validation\"\n"
      ],
      "metadata": {
        "id": "0qQMS5z2G1Yp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This copies the dataset from Drive to the Colab instance's local temporary storage (/content/)\n",
        "# Path on Google Drive\n",
        "source_dir = \"/content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset\"\n",
        "# Path on local Colab machine\n",
        "local_dir = \"/content/plant_data\"\n",
        "\n",
        "if not os.path.exists(local_dir):\n",
        "    shutil.copytree(source_dir, local_dir)\n",
        "print(\"Copy complete!\")\n",
        "\n",
        "dataset_path = local_dir\n",
        "train_dir = dataset_path + \"/train\"\n",
        "validation_dir = dataset_path + \"/validation\""
      ],
      "metadata": {
        "id": "HRRiNI5gchkD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c52a47e-1ceb-41b1-d0ae-8832e45fe7f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define standard ResNet transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # ResNet expects 224x224\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "train_dataset = ImageFolder(train_dir, transform=data_transforms['train'])\n",
        "val_dataset = ImageFolder(validation_dir, transform=data_transforms['validation'])\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")"
      ],
      "metadata": {
        "id": "LMt5-7lJ-loL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(torch.cuda.get_device_name(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rjwHpZqbogp",
        "outputId": "6f41f4a6-85ac-4fa8-fdd8-3521836b4d15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA A100-SXM4-40GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bf36678",
        "outputId": "58c23ca6-f71f-424b-d682-6e40a56d73e4"
      },
      "source": [
        "# Load pre-trained ResNet50 model\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "# Freeze parameters\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Calculate num_classes from the DATASET, not the directory string\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(f\"Detected {num_classes} classes.\")\n",
        "\n",
        "# Replace final layer\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "# Move to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "print(f\"Model created and moved to {device}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 118MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected 23 classes.\n",
            "Model created and moved to cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Define the Loss Function\n",
        "# CrossEntropyLoss is the standard for multi-class classification\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 2. Define the Optimizer\n",
        "# We only pass model.fc.parameters() because we froze the rest of the network\n",
        "# Learning rate (lr) of 0.001 is a good starting point\n",
        "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function and Optimizer defined.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPhBA6JkUlgF",
        "outputId": "39f0cb85-fdfb-442d-eab2-f6add5b247fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss function and Optimizer defined.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50\n",
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    start_time = time.time()\n",
        "    # Store history to plot later\n",
        "    train_acc_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    print(f\"Starting training on {device}...\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                data_loader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                data_loader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data (batches)\n",
        "            for inputs, labels in data_loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward Pass\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # Backward Pass + Optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # Statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(data_loader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(data_loader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Save history\n",
        "            if phase == 'train':\n",
        "                train_acc_history.append(epoch_acc.item())\n",
        "            else:\n",
        "                val_acc_history.append(epoch_acc.item())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - start_time\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "\n",
        "    return model, train_acc_history, val_acc_history\n",
        "\n",
        "# 3. Run the training\n",
        "trained_model, train_acc, val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMYMmA1eUruE",
        "outputId": "45791fec-e132-4d83-c009-4db4dd0e39fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training on cuda...\n",
            "Epoch 1/20\n",
            "----------\n",
            "train Loss: 0.1268 Acc: 0.9595\n",
            "val Loss: 0.1120 Acc: 0.9639\n",
            "\n",
            "Epoch 2/20\n",
            "----------\n",
            "train Loss: 0.1172 Acc: 0.9632\n",
            "val Loss: 0.1028 Acc: 0.9697\n",
            "\n",
            "Epoch 3/20\n",
            "----------\n",
            "train Loss: 0.1053 Acc: 0.9665\n",
            "val Loss: 0.0936 Acc: 0.9711\n",
            "\n",
            "Epoch 4/20\n",
            "----------\n",
            "train Loss: 0.0988 Acc: 0.9679\n",
            "val Loss: 0.0838 Acc: 0.9745\n",
            "\n",
            "Epoch 5/20\n",
            "----------\n",
            "train Loss: 0.0955 Acc: 0.9689\n",
            "val Loss: 0.0853 Acc: 0.9742\n",
            "\n",
            "Epoch 6/20\n",
            "----------\n",
            "train Loss: 0.0916 Acc: 0.9691\n",
            "val Loss: 0.0866 Acc: 0.9721\n",
            "\n",
            "Epoch 7/20\n",
            "----------\n",
            "train Loss: 0.0882 Acc: 0.9698\n",
            "val Loss: 0.0781 Acc: 0.9747\n",
            "\n",
            "Epoch 8/20\n",
            "----------\n",
            "train Loss: 0.0846 Acc: 0.9715\n",
            "val Loss: 0.0734 Acc: 0.9780\n",
            "\n",
            "Epoch 9/20\n",
            "----------\n",
            "train Loss: 0.0777 Acc: 0.9742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path in your Google Drive\n",
        "save_path = '/content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset/models/plant_disease_resnet50.pth'\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(f\"Model saved successfully to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCAcZdWNrjaA",
        "outputId": "709832a5-f5fa-4aa6-b28f-4bf23eb41a55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully to: /content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset/models/plant_disease_resnet50.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# YOLOv8\n",
        "dataset_path = \"/content/plant_data\"\n",
        "\n",
        "model = YOLO(\"yolov8s-cls.pt\")\n",
        "\n",
        "# Train YOLO classification model\n",
        "results = model.train(\n",
        "    data=dataset_path,\n",
        "    epochs=20,\n",
        "    imgsz=224,\n",
        "    batch=64,\n",
        "    lr0=0.001,\n",
        "    device=0  # GPU\n",
        ")\n",
        "\n",
        "print(\"Training finished!\")\n",
        "\n",
        "save_path = \"/content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset/models\"\n",
        "os.makedirs(save_path, exist_ok=True)\n",
        "\n",
        "# Define where YOLO saved the weights\n",
        "# Note: The files are ALWAYS named 'best.pt' and 'last.pt' inside that folder\n",
        "local_best = \"runs/classify/train/weights/best.pt\"\n",
        "local_last = \"runs/classify/train/weights/last.pt\"\n",
        "\n",
        "# Copy and Rename to Drive\n",
        "# We rename them to 'yolo_best.pt' while copying so they don't get mixed up in Drive\n",
        "shutil.copy(local_best, os.path.join(save_path, \"yolo_best.pt\"))\n",
        "shutil.copy(local_last, os.path.join(save_path, \"yolo_last.pt\"))\n",
        "\n",
        "print(f\"Models saved to: {save_path}\")"
      ],
      "metadata": {
        "id": "cAnMLklUmCSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be016e74-28c3-489b-87b4-7c8d9b9867cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s-cls.pt to 'yolov8s-cls.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 12.3MB 103.8MB/s 0.1s\n",
            "Ultralytics 8.3.235 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=64, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/plant_data, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=20, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=224, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.001, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-cls.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/runs/classify/train, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=classify, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/plant_data/train... found 31971 images in 23 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/plant_data/validation... found 10512 images in 23 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "Overriding model.yaml nc=1000 with nc=23\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    687383  ultralytics.nn.modules.head.Classify         [512, 23]                     \n",
            "YOLOv8s-cls summary: 56 layers, 5,110,199 parameters, 5,110,199 gradients, 12.6 GFLOPs\n",
            "Transferred 156/158 items from pretrained weights\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 63.7MB/s 0.1s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 413.5Â±173.6 MB/s, size: 10.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/plant_data/train... 31971 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 31971/31971 3.4Kit/s 9.5s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/plant_data/train.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 364.0Â±127.3 MB/s, size: 12.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/plant_data/validation... 10512 images, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 10512/10512 3.3Kit/s 3.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/plant_data/validation.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.001' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00037, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n",
            "Image sizes 224 train, 224 val\n",
            "Using 8 dataloader workers\n",
            "Logging results to \u001b[1m/content/runs/classify/train\u001b[0m\n",
            "Starting training for 20 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 14.0MB/s 0.1s\n",
            "\u001b[K       1/20      1.34G      1.586         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 15.7it/s 31.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.6it/s 4.2s\n",
            "                   all      0.943      0.999\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       2/20      1.69G     0.1941         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.5it/s 28.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 17.5it/s 4.7s\n",
            "                   all      0.973          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       3/20       1.7G     0.1201         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 16.9it/s 29.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 20.7it/s 4.0s\n",
            "                   all      0.981          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       4/20      1.71G    0.09323         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.1it/s 29.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 20.2it/s 4.1s\n",
            "                   all      0.988          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       5/20      1.72G    0.07075         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 16.8it/s 29.8s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.7it/s 4.2s\n",
            "                   all      0.992          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       6/20      1.73G    0.05883         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.1it/s 29.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 18.3it/s 4.5s\n",
            "                   all      0.993          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       7/20      1.75G    0.05225         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.0it/s 29.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.4it/s 4.3s\n",
            "                   all      0.995          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       8/20      1.76G    0.04342         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.1it/s 29.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 21.8it/s 3.8s\n",
            "                   all      0.993          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K       9/20      1.77G    0.03779         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.0it/s 29.3s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 18.7it/s 4.4s\n",
            "                   all      0.994          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      10/20      1.78G    0.03431         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 16.9it/s 29.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 18.9it/s 4.4s\n",
            "                   all      0.996          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      11/20      1.79G    0.03059         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 15.8it/s 31.7s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 20.3it/s 4.1s\n",
            "                   all      0.996          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      12/20      1.81G    0.02848         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.5it/s 28.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.4it/s 4.3s\n",
            "                   all      0.997          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      13/20      1.82G    0.02407         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.2it/s 29.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.4it/s 4.3s\n",
            "                   all      0.997          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      14/20      1.83G    0.02212         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.6it/s 28.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 18.9it/s 4.4s\n",
            "                   all      0.998          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      15/20      1.84G    0.01883         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.6it/s 28.4s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.3it/s 4.3s\n",
            "                   all      0.998          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      16/20      1.85G    0.01917         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.6it/s 28.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 18.9it/s 4.4s\n",
            "                   all      0.998          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      17/20      1.87G     0.0161         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.3it/s 28.9s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.1it/s 4.3s\n",
            "                   all      0.998          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      18/20      1.88G    0.01504         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.2it/s 29.0s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 21.0it/s 4.0s\n",
            "                   all      0.998          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      19/20      1.89G    0.01248         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.5it/s 28.5s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 20.6it/s 4.0s\n",
            "                   all      0.998          1\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "\u001b[K      20/20       1.9G    0.01156         35        224: 100% â”â”â”â”â”â”â”â”â”â”â”â” 500/500 17.5it/s 28.6s\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 19.2it/s 4.3s\n",
            "                   all      0.998          1\n",
            "\n",
            "20 epochs completed in 0.189 hours.\n",
            "Optimizer stripped from /content/runs/classify/train/weights/last.pt, 10.3MB\n",
            "Optimizer stripped from /content/runs/classify/train/weights/best.pt, 10.3MB\n",
            "\n",
            "Validating /content/runs/classify/train/weights/best.pt...\n",
            "Ultralytics 8.3.235 ðŸš€ Python-3.12.12 torch-2.9.0+cu126 CUDA:0 (NVIDIA A100-SXM4-40GB, 40507MiB)\n",
            "YOLOv8s-cls summary (fused): 30 layers, 5,104,663 parameters, 0 gradients, 12.5 GFLOPs\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/plant_data/train... found 31971 images in 23 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/plant_data/validation... found 10512 images in 23 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m None...\n",
            "\u001b[K               classes   top1_acc   top5_acc: 100% â”â”â”â”â”â”â”â”â”â”â”â” 83/83 20.3it/s 4.1s\n",
            "                   all      0.998          1\n",
            "Speed: 0.1ms preprocess, 0.1ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/classify/train\u001b[0m\n",
            "Training finished!\n",
            "Models saved to: /content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MobileNetV3-Small\n",
        "model_mnet = models.mobilenet_v3_small(pretrained=True)\n",
        "for param in model_mnet.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Compute number of classes dynamically\n",
        "num_classes = len(train_dataset.classes)\n",
        "print(f\"Detected {num_classes} classes for MobileNetV3-Small.\")\n",
        "\n",
        "# Replace classifier head\n",
        "# Default structure: model_mnet.classifier = Sequential(...)\n",
        "in_features = model_mnet.classifier[3].in_features\n",
        "model_mnet.classifier[3] = nn.Linear(in_features, num_classes)\n",
        "\n",
        "# Move to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model_mnet = model_mnet.to(device)\n",
        "print(\"MobileNetV3-Small model created and moved to\", device)\n",
        "\n",
        "# --- Loss & Optimizer ---\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model_mnet.classifier.parameters(), lr=0.001)\n",
        "\n",
        "print(\"Loss function and optimizer ready.\")"
      ],
      "metadata": {
        "id": "3Gd18LNE0OFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_mobilenet(model, train_loader, val_loader, criterion, optimizer, num_epochs=20):\n",
        "    start_time = time.time()\n",
        "    best_acc = 0.0\n",
        "    save_dir = \"runs/classify/mobilenet/weights\"\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
        "        print(\"-\" * 10)\n",
        "\n",
        "        for phase in [\"train\", \"val\"]:\n",
        "            if phase == \"train\":\n",
        "                model.train()\n",
        "                loader = train_loader\n",
        "            else:\n",
        "                model.eval()\n",
        "                loader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in loader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                with torch.set_grad_enabled(phase == \"train\"):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    if phase == \"train\":\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(loader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(loader.dataset)\n",
        "\n",
        "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "            # Save best model (only from validation phase)\n",
        "            if phase == \"val\":\n",
        "                # Save \"last.pt\" every epoch\n",
        "                torch.save(model.state_dict(), os.path.join(save_dir, \"last.pt\"))\n",
        "\n",
        "                # Save \"best.pt\" if accuracy improved\n",
        "                if epoch_acc > best_acc:\n",
        "                    best_acc = epoch_acc\n",
        "                    torch.save(model.state_dict(), os.path.join(save_dir, \"best.pt\"))\n",
        "                    print(\"Best model updated!\")\n",
        "\n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nTraining completed in {total_time//60:.0f}m {total_time%60:.0f}s\")\n",
        "    print(f\"Best validation accuracy: {best_acc:.4f}\")\n",
        "    print(f\"Models saved to {save_dir}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# Run Training\n",
        "mobilenet_model = train_mobilenet(\n",
        "    model_mnet, train_loader, val_loader, criterion, optimizer, num_epochs=20\n",
        ")\n",
        "\n",
        "# Save Model\n",
        "drive_save_dir = \"/content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset/models/mobilenetv3\"\n",
        "os.makedirs(drive_save_dir, exist_ok=True)\n",
        "\n",
        "shutil.copy(\"runs/classify/mobilenet/weights/best.pt\", os.path.join(drive_save_dir, \"mobilenet_best.pt\"))\n",
        "shutil.copy(\"runs/classify/mobilenet/weights/last.pt\", os.path.join(drive_save_dir, \"mobilenet_last.pt\"))\n",
        "\n",
        "print(f\"\\nMobileNet models copied to Drive folder:\\n{drive_save_dir}\")"
      ],
      "metadata": {
        "id": "pRcVR-c40prc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 2. Define Transforms for EfficientNetV2\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((384, 384)), # Resize to 384\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'validation': transforms.Compose([\n",
        "        transforms.Resize((384, 384)), # Resize to 384\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "dataset_path = \"/content/plant_data\"\n",
        "train_dataset = ImageFolder(dataset_path + \"/train\", transform=data_transforms['train'])\n",
        "val_dataset = ImageFolder(dataset_path + \"/validation\", transform=data_transforms['validation'])\n",
        "\n",
        "batch_size = 32\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# 4. Setup Model\n",
        "weights = models.EfficientNet_V2_S_Weights.IMAGENET1K_V1\n",
        "model = models.efficientnet_v2_s(weights=weights)\n",
        "\n",
        "# FREEZE the backbone (Feature Extractor)\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Replace the Classifier Head\n",
        "# EfficientNet's classifier is a Sequential block: [0]=Dropout, [1]=Linear\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# 5. Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Optimize ONLY the classifier parameters (since backbone is frozen)\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "g3HzTlQO_Xsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
        "    since = time.time()\n",
        "\n",
        "    val_acc_history = []\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model if it's the best one so far\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            if phase == 'val':\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, val_acc_history, val_acc_history"
      ],
      "metadata": {
        "id": "CQ4geu37FJ47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting training...\")\n",
        "model, train_acc, val_acc = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "save_path = '/content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset/models/plant_disease_efficientnetv2.pth'\n",
        "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
        "torch.save(model.state_dict(), save_path)\n",
        "\n",
        "print(f\"Model trained and saved to: {save_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsO10S27Cp-R",
        "outputId": "1499aa68-0b8d-4d48-c9b6-57a7a31dacae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "Epoch 1/10\n",
            "----------\n",
            "train Loss: 0.8021 Acc: 0.8164\n",
            "val Loss: 0.3456 Acc: 0.9167\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n",
            "train Loss: 0.3728 Acc: 0.8963\n",
            "val Loss: 0.2486 Acc: 0.9340\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n",
            "train Loss: 0.3056 Acc: 0.9088\n",
            "val Loss: 0.1986 Acc: 0.9447\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n",
            "train Loss: 0.2738 Acc: 0.9164\n",
            "val Loss: 0.1790 Acc: 0.9489\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n",
            "train Loss: 0.2579 Acc: 0.9186\n",
            "val Loss: 0.1641 Acc: 0.9521\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n",
            "train Loss: 0.2454 Acc: 0.9209\n",
            "val Loss: 0.1530 Acc: 0.9534\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n",
            "train Loss: 0.2387 Acc: 0.9226\n",
            "val Loss: 0.1387 Acc: 0.9578\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n",
            "train Loss: 0.2323 Acc: 0.9270\n",
            "val Loss: 0.1409 Acc: 0.9586\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n",
            "train Loss: 0.2248 Acc: 0.9260\n",
            "val Loss: 0.1371 Acc: 0.9571\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n",
            "train Loss: 0.2226 Acc: 0.9271\n",
            "val Loss: 0.1271 Acc: 0.9600\n",
            "\n",
            "Training complete in 19m 40s\n",
            "Best val Acc: 0.960046\n",
            "Model trained and saved to: /content/drive/MyDrive/Colab Notebooks/Plant Disease Dataset/models/plant_disease_efficientnetv2.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4dOjXldpicwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}